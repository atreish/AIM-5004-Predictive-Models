{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atreish Ramlakhan\n",
    "AIM 5004: Predictive Models\n",
    "Summer 2021\n",
    "HW #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atreish/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sampling from the standard normal distribution, independently generate 500 observations for 101 variables. Call the first of these variables the response variable Y and the other variables the predictors X1;X2;...;X100. Perform a linear least-squares regression of Y on X1;X2;...;X100. Are any of the individual regression coefficients ‘‘statistically significant’’? Is the omnibus F-statistic for the regression ‘‘statistically significant’’? Is this what you expected to observe? (Hint: What are the ‘‘true’’ values of the regression coefficients β1;β2;...;β100?)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.462438</td>\n",
       "      <td>1.249499</td>\n",
       "      <td>-0.854919</td>\n",
       "      <td>-0.156918</td>\n",
       "      <td>1.243443</td>\n",
       "      <td>-1.299536</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>1.623889</td>\n",
       "      <td>0.210216</td>\n",
       "      <td>0.686175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633980</td>\n",
       "      <td>0.384545</td>\n",
       "      <td>-0.254027</td>\n",
       "      <td>-0.965206</td>\n",
       "      <td>-0.711263</td>\n",
       "      <td>-1.616579</td>\n",
       "      <td>-1.079203</td>\n",
       "      <td>1.518865</td>\n",
       "      <td>0.951945</td>\n",
       "      <td>-0.433185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.173195</td>\n",
       "      <td>-0.864177</td>\n",
       "      <td>-0.840873</td>\n",
       "      <td>-0.365763</td>\n",
       "      <td>-0.065291</td>\n",
       "      <td>0.482392</td>\n",
       "      <td>-1.027042</td>\n",
       "      <td>-0.366683</td>\n",
       "      <td>-1.000319</td>\n",
       "      <td>0.212296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055218</td>\n",
       "      <td>1.102226</td>\n",
       "      <td>-1.787366</td>\n",
       "      <td>1.111214</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>0.370114</td>\n",
       "      <td>0.360313</td>\n",
       "      <td>-1.418004</td>\n",
       "      <td>0.229284</td>\n",
       "      <td>-2.196471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.190787</td>\n",
       "      <td>1.456419</td>\n",
       "      <td>-1.951259</td>\n",
       "      <td>0.300122</td>\n",
       "      <td>-0.195449</td>\n",
       "      <td>-0.452137</td>\n",
       "      <td>-0.022438</td>\n",
       "      <td>-0.568317</td>\n",
       "      <td>-0.809723</td>\n",
       "      <td>1.368912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235538</td>\n",
       "      <td>-1.307140</td>\n",
       "      <td>0.897892</td>\n",
       "      <td>0.505982</td>\n",
       "      <td>-2.019726</td>\n",
       "      <td>-1.028541</td>\n",
       "      <td>-0.438110</td>\n",
       "      <td>0.015779</td>\n",
       "      <td>1.473614</td>\n",
       "      <td>1.213371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.968708</td>\n",
       "      <td>-1.140163</td>\n",
       "      <td>1.502828</td>\n",
       "      <td>-1.043068</td>\n",
       "      <td>-1.131375</td>\n",
       "      <td>0.553749</td>\n",
       "      <td>-0.630414</td>\n",
       "      <td>0.624702</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>0.562938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.969043</td>\n",
       "      <td>0.243171</td>\n",
       "      <td>1.106980</td>\n",
       "      <td>-0.561127</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>-0.888232</td>\n",
       "      <td>1.560001</td>\n",
       "      <td>-0.600662</td>\n",
       "      <td>0.341168</td>\n",
       "      <td>0.644471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016130</td>\n",
       "      <td>-0.649337</td>\n",
       "      <td>0.378621</td>\n",
       "      <td>-0.819794</td>\n",
       "      <td>-1.247142</td>\n",
       "      <td>0.901642</td>\n",
       "      <td>-0.475260</td>\n",
       "      <td>-2.096256</td>\n",
       "      <td>0.141616</td>\n",
       "      <td>0.245696</td>\n",
       "      <td>...</td>\n",
       "      <td>1.308003</td>\n",
       "      <td>1.689333</td>\n",
       "      <td>1.558682</td>\n",
       "      <td>-0.882625</td>\n",
       "      <td>1.496182</td>\n",
       "      <td>-2.411403</td>\n",
       "      <td>-0.596461</td>\n",
       "      <td>0.117853</td>\n",
       "      <td>-1.734250</td>\n",
       "      <td>0.468550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.564076</td>\n",
       "      <td>-1.829863</td>\n",
       "      <td>1.077071</td>\n",
       "      <td>1.545839</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>-0.477449</td>\n",
       "      <td>0.138563</td>\n",
       "      <td>-1.048737</td>\n",
       "      <td>0.078724</td>\n",
       "      <td>0.487980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673519</td>\n",
       "      <td>0.279926</td>\n",
       "      <td>0.837161</td>\n",
       "      <td>-0.566015</td>\n",
       "      <td>-0.436590</td>\n",
       "      <td>-1.279096</td>\n",
       "      <td>-1.106594</td>\n",
       "      <td>-0.419741</td>\n",
       "      <td>1.302827</td>\n",
       "      <td>1.112291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.557576</td>\n",
       "      <td>-1.362494</td>\n",
       "      <td>-0.267444</td>\n",
       "      <td>1.297564</td>\n",
       "      <td>0.104944</td>\n",
       "      <td>-0.677416</td>\n",
       "      <td>2.676790</td>\n",
       "      <td>-0.179809</td>\n",
       "      <td>1.584800</td>\n",
       "      <td>-0.036809</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.831816</td>\n",
       "      <td>1.058493</td>\n",
       "      <td>0.336551</td>\n",
       "      <td>0.983894</td>\n",
       "      <td>0.617846</td>\n",
       "      <td>-0.387183</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>0.780457</td>\n",
       "      <td>-1.853994</td>\n",
       "      <td>-1.408086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-0.921775</td>\n",
       "      <td>0.608079</td>\n",
       "      <td>-0.481006</td>\n",
       "      <td>-0.054649</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>-0.518268</td>\n",
       "      <td>-0.685783</td>\n",
       "      <td>0.558615</td>\n",
       "      <td>2.207591</td>\n",
       "      <td>-1.569929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273121</td>\n",
       "      <td>-0.359258</td>\n",
       "      <td>1.236156</td>\n",
       "      <td>-0.445148</td>\n",
       "      <td>-0.155735</td>\n",
       "      <td>-1.140359</td>\n",
       "      <td>0.545758</td>\n",
       "      <td>-1.856937</td>\n",
       "      <td>1.425301</td>\n",
       "      <td>-2.343111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.244553</td>\n",
       "      <td>-1.233810</td>\n",
       "      <td>0.207088</td>\n",
       "      <td>-0.340393</td>\n",
       "      <td>0.048040</td>\n",
       "      <td>0.959811</td>\n",
       "      <td>-1.114824</td>\n",
       "      <td>0.912383</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>1.161339</td>\n",
       "      <td>...</td>\n",
       "      <td>1.711606</td>\n",
       "      <td>-0.296404</td>\n",
       "      <td>0.097662</td>\n",
       "      <td>-0.926645</td>\n",
       "      <td>2.123785</td>\n",
       "      <td>-0.846994</td>\n",
       "      <td>0.230518</td>\n",
       "      <td>-1.454774</td>\n",
       "      <td>1.175853</td>\n",
       "      <td>-0.833761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.572667</td>\n",
       "      <td>2.052523</td>\n",
       "      <td>-0.894325</td>\n",
       "      <td>1.208077</td>\n",
       "      <td>-0.733865</td>\n",
       "      <td>-0.492318</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>-1.105038</td>\n",
       "      <td>-0.098794</td>\n",
       "      <td>0.914132</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.301452</td>\n",
       "      <td>-0.491802</td>\n",
       "      <td>0.622277</td>\n",
       "      <td>-0.223710</td>\n",
       "      <td>-0.042735</td>\n",
       "      <td>-1.613719</td>\n",
       "      <td>-0.654293</td>\n",
       "      <td>-0.201657</td>\n",
       "      <td>1.007477</td>\n",
       "      <td>0.389884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0   -1.462438  1.249499 -0.854919 -0.156918  1.243443 -1.299536 -0.046793   \n",
       "1    0.173195 -0.864177 -0.840873 -0.365763 -0.065291  0.482392 -1.027042   \n",
       "2    0.190787  1.456419 -1.951259  0.300122 -0.195449 -0.452137 -0.022438   \n",
       "3    0.968708 -1.140163  1.502828 -1.043068 -1.131375  0.553749 -0.630414   \n",
       "4    0.016130 -0.649337  0.378621 -0.819794 -1.247142  0.901642 -0.475260   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "495  0.564076 -1.829863  1.077071  1.545839  0.040963 -0.477449  0.138563   \n",
       "496 -0.557576 -1.362494 -0.267444  1.297564  0.104944 -0.677416  2.676790   \n",
       "497 -0.921775  0.608079 -0.481006 -0.054649  0.598365 -0.518268 -0.685783   \n",
       "498  0.244553 -1.233810  0.207088 -0.340393  0.048040  0.959811 -1.114824   \n",
       "499  0.572667  2.052523 -0.894325  1.208077 -0.733865 -0.492318 -0.000658   \n",
       "\n",
       "          7         8         9    ...       91        92        93   \\\n",
       "0    1.623889  0.210216  0.686175  ... -0.633980  0.384545 -0.254027   \n",
       "1   -0.366683 -1.000319  0.212296  ... -0.055218  1.102226 -1.787366   \n",
       "2   -0.568317 -0.809723  1.368912  ...  0.235538 -1.307140  0.897892   \n",
       "3    0.624702  0.438316  0.562938  ...  1.969043  0.243171  1.106980   \n",
       "4   -2.096256  0.141616  0.245696  ...  1.308003  1.689333  1.558682   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "495 -1.048737  0.078724  0.487980  ...  0.673519  0.279926  0.837161   \n",
       "496 -0.179809  1.584800 -0.036809  ... -1.831816  1.058493  0.336551   \n",
       "497  0.558615  2.207591 -1.569929  ...  0.273121 -0.359258  1.236156   \n",
       "498  0.912383  0.031456  1.161339  ...  1.711606 -0.296404  0.097662   \n",
       "499 -1.105038 -0.098794  0.914132  ... -1.301452 -0.491802  0.622277   \n",
       "\n",
       "          94        95        96        97        98        99        100  \n",
       "0   -0.965206 -0.711263 -1.616579 -1.079203  1.518865  0.951945 -0.433185  \n",
       "1    1.111214  0.034570  0.370114  0.360313 -1.418004  0.229284 -2.196471  \n",
       "2    0.505982 -2.019726 -1.028541 -0.438110  0.015779  1.473614  1.213371  \n",
       "3   -0.561127  0.832050 -0.888232  1.560001 -0.600662  0.341168  0.644471  \n",
       "4   -0.882625  1.496182 -2.411403 -0.596461  0.117853 -1.734250  0.468550  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "495 -0.566015 -0.436590 -1.279096 -1.106594 -0.419741  1.302827  1.112291  \n",
       "496  0.983894  0.617846 -0.387183 -0.032541  0.780457 -1.853994 -1.408086  \n",
       "497 -0.445148 -0.155735 -1.140359  0.545758 -1.856937  1.425301 -2.343111  \n",
       "498 -0.926645  2.123785 -0.846994  0.230518 -1.454774  1.175853 -0.833761  \n",
       "499 -0.223710 -0.042735 -1.613719 -0.654293 -0.201657  1.007477  0.389884  \n",
       "\n",
       "[500 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate the data, which is a 500x101 matrix with each having data from ~N(0,1) for each row\n",
    "arr = np.random.normal(0, 1, size=(500, 101))\n",
    "data = pd.DataFrame(arr)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Does the 1st column look Normal?\n",
    "plt.hist(data.iloc[:,0], bins=70, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2nd column\n",
    "plt.hist(data.iloc[:,1], bins=70, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Call the first of these variables the response variable Y and the other variables the predictors X1;X2;...;X100. Perform a linear least-squares regression of Y on X1;X2;...;X100.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#response variable will be he first column\n",
    "y = data[0]\n",
    "#x1-x100 explanatory variables\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "#Apply scikitLearn's Linear Regression function\n",
    "Reg1 = LinearRegression().fit(X, y)\n",
    "#Call the Array of Coefficients we called from the above function \n",
    "coefs = Reg1.coef_\n",
    "#Calculate the intercept for the Regression\n",
    "intercept = Reg1.intercept_\n",
    "#ensure that there are 100 coefficients for our regression + 1 intercept to acocunt for 101 columns/variables\n",
    "len(coefs) #verify we have 100 coefficients for our regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01333293  0.00049237 -0.04643279  0.01255026  0.11868308  0.01745557\n",
      " -0.0399769   0.11335041  0.00959495  0.01696245 -0.01389303 -0.040371\n",
      " -0.08733068 -0.08740634  0.0364788   0.0284914  -0.09122998  0.13461365\n",
      " -0.01145294  0.03561219  0.06241574  0.02255288  0.04826005  0.08939496\n",
      " -0.07536497  0.05331776  0.00143677 -0.02690765  0.04549763 -0.01837777\n",
      "  0.05645788 -0.06093207 -0.00992787  0.0104681  -0.12902163  0.00213122\n",
      "  0.00507771 -0.01946293  0.02056683 -0.01406745  0.01997488  0.01247469\n",
      "  0.01747016 -0.10571717  0.05493484 -0.02616372 -0.01185346 -0.00534009\n",
      "  0.05657466  0.00117198 -0.07759684 -0.01604952  0.11489481  0.00162874\n",
      " -0.0113768  -0.01818944  0.0271307   0.01342993  0.05879948 -0.04547849\n",
      "  0.09022874  0.05465338 -0.0883023  -0.00497107 -0.02977133 -0.06356518\n",
      " -0.07951857  0.05049459 -0.06447298 -0.01170047  0.04666677 -0.01943209\n",
      " -0.04037808  0.09430443 -0.01738677  0.09817995 -0.00399811  0.0957549\n",
      " -0.01844015  0.08171167  0.00813948  0.01473943 -0.1181335  -0.02605951\n",
      " -0.03998387 -0.03153962  0.04145459  0.04079274  0.04721843  0.04337264\n",
      "  0.02121748  0.01251145 -0.09497157  0.04697345  0.02849731 -0.02635468\n",
      " -0.05324732 -0.03529019  0.0472009   0.01341574]\n",
      "\n",
      "0.050490305937766496\n"
     ]
    }
   ],
   "source": [
    "print(coefs)\n",
    "print('')\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Are any of the individual regression coefficients ‘‘statistically significant’’?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77704825, 0.99083342, 0.27102499, 0.78693848, 0.00793823,\n",
       "       0.69907788, 0.37013477, 0.00892089, 0.82715703, 0.71422014,\n",
       "       0.76929806, 0.36100964, 0.05085182, 0.06041016, 0.40865121,\n",
       "       0.53847727, 0.05928927, 0.00257312, 0.79957986, 0.39866611,\n",
       "       0.14449203, 0.60079536, 0.29533765, 0.02603798, 0.08725982,\n",
       "       0.21996232, 0.97553339, 0.55158046, 0.29932893, 0.69052341,\n",
       "       0.225405  , 0.14637464, 0.82552384, 0.81947607, 0.00342529,\n",
       "       0.95933844, 0.9075658 , 0.66351399, 0.64532842, 0.75089208,\n",
       "       0.62592146, 0.79761981, 0.70009107, 0.01912297, 0.20967597,\n",
       "       0.5468643 , 0.7954473 , 0.90240793, 0.19246485, 0.97774293,\n",
       "       0.08589381, 0.72099908, 0.0116605 , 0.97288802, 0.79152493,\n",
       "       0.69618462, 0.55039306, 0.75787695, 0.19129195, 0.29577114,\n",
       "       0.04405617, 0.2097376 , 0.04576617, 0.91260984, 0.50982765,\n",
       "       0.1480692 , 0.08727037, 0.24400364, 0.14867715, 0.7894453 ,\n",
       "       0.28038941, 0.66419595, 0.35128515, 0.04368865, 0.71639363,\n",
       "       0.03375956, 0.93031542, 0.03071101, 0.68505564, 0.07302632,\n",
       "       0.85906444, 0.745665  , 0.00819707, 0.55738187, 0.38567885,\n",
       "       0.49914192, 0.36230349, 0.36566036, 0.28413089, 0.3120329 ,\n",
       "       0.66066954, 0.77372169, 0.02823241, 0.27439145, 0.52484509,\n",
       "       0.57009289, 0.25534681, 0.43356496, 0.27531117, 0.77263325])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To answer this question, we must first calculate the p-Value for each explanatory variable\n",
    "\n",
    "#First we calculate T-scores based on formula as an array\n",
    "t_scores = coefs/(np.std(X)/np.sqrt(500))\n",
    "#Now use the scipy.stats.t.sf method to get p-values\n",
    "p_values = scipy.stats.t.sf(np.abs(t_scores), df=500)*2\n",
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8, 18, 24, 35, 44, 53, 61, 63, 74, 76, 78, 83, 93]\n",
      "\n",
      "0.007938231680512164\n",
      "0.008920894140401647\n",
      "0.0025731160770666364\n",
      "0.026037979632494594\n",
      "0.003425292744851636\n",
      "0.019122971853910577\n",
      "0.011660500759653199\n",
      "0.044056166550253205\n",
      "0.04576616744340905\n",
      "0.04368864670953445\n",
      "0.033759560304500044\n",
      "0.03071101332633917\n",
      "0.008197067498248351\n",
      "0.028232408402401717\n"
     ]
    }
   ],
   "source": [
    "'''Now we determine if any of the above entries are below the 5% significance level to reject\n",
    "the null hypothesis for our coefficients'''\n",
    "\n",
    "alpha = 0.05\n",
    "index = 0\n",
    "n_index = []\n",
    "for i in p_values:\n",
    "    index+=1\n",
    "    # if in the reject zone\n",
    "    if i < alpha:\n",
    "        n_index.append(index)\n",
    "print(n_index)\n",
    "print('')\n",
    "\n",
    "#Print these p_values that are statistically significant\n",
    "for j in n_index:\n",
    "    print(p_values[j-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Is the omnibus F-statistic for the regression ‘‘statistically significant’’? Is this what you expected to observe? (Hint: What are the ‘‘true’’ values of the regression coefficients β1;β2;...;β100?)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F-Statistic for this data is = 1.1391748281640006\n",
      "\n",
      "The p-value for the F-Statistic is = 0.19340917074425557\n"
     ]
    }
   ],
   "source": [
    "'''To determine the p_value for the F-statistic we first calculate it then determine if it is less than\n",
    "the 5% significance level. To get the F-statistic we need to calculate the R^2'''\n",
    "\n",
    "y_hat = Reg1.predict(X) #can our regression predict X?\n",
    "y_mean = np.mean(y)\n",
    "RSS = sum((y-y_hat)**2)\n",
    "TSS = sum((y-y_mean)**2)\n",
    "RegSS = TSS-RSS\n",
    "R2 = RegSS/TSS \n",
    "\n",
    "F_statistic_a = (R2/100)/((1-R2)/(399))\n",
    "print('The F-Statistic for this data is = {}'.format(F_statistic_a))\n",
    "print('')\n",
    "p_value_f_stat_a = 1 - scipy.stats.f.cdf(F_statistic_a,100,400)\n",
    "print('The p-value for the F-Statistic is = {}'.format(p_value_f_stat_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-values is way above the 5% threshold, the F-statistic for this data is not significant. We would in fact accept the Null hypothesis. This is not what I would expect since the values of the coefficients are not all =0 but it doesnt surprise me because the Standard Normal distribution usually has alot of interesting properities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Retain the three predictors in part (a) that have the largest absolute t-values, regressing Y only on these variables. Are the individual coefficients ‘‘statistically significant’’? What about the omnibus F? What happens to the p-values compared to part (a)?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0.283321\n",
       "2      0.011495\n",
       "3     -1.101924\n",
       "4      0.270433\n",
       "5      2.665408\n",
       "         ...   \n",
       "96    -0.568290\n",
       "97    -1.138764\n",
       "98    -0.783738\n",
       "99     1.092109\n",
       "100    0.289089\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Highlight top 3 values in t-scores list list \n",
    "t_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([18, 35, 5], dtype='int64')\n",
      "\n",
      "18    3.029884\n",
      "35   -2.940806\n",
      "5     2.665408\n",
      "dtype: float64\n",
      "\n",
      "           18        35        5 \n",
      "0   -0.846473 -0.307555 -1.299536\n",
      "1    1.476585  0.616042  0.482392\n",
      "2   -0.622645 -1.445672 -0.452137\n",
      "3    0.400749 -0.295170  0.553749\n",
      "4   -2.078175 -0.357174  0.901642\n",
      "..        ...       ...       ...\n",
      "495 -0.531491 -0.901827 -0.477449\n",
      "496 -0.984987  1.414630 -0.677416\n",
      "497  0.419495  1.587792 -0.518268\n",
      "498  1.311165 -0.909095  0.959811\n",
      "499  0.507849 -1.944145 -0.492318\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "top3_tscores = abs(t_scores).sort_values(ascending=False).index[:3]\n",
    "print(top3_tscores)\n",
    "print('')\n",
    "top3tvalues = t_scores[top3_tscores]\n",
    "print(top3tvalues)\n",
    "print('')\n",
    "x2 = X[top3_tscores]\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`regressing Y only on these variables.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12445447 -0.11684056  0.0717708 ]\n",
      "\n",
      "0.04381792854695335\n"
     ]
    }
   ],
   "source": [
    "#Now we run another Regression using the same procedure as above but with only a df of the 3 cols marked as x2\n",
    "reg2 = LinearRegression().fit(x2, y) #our y column is the same as our original y for 1st experiment\n",
    "coefs2 = reg2.coef_\n",
    "intercept2 = reg2.intercept_\n",
    "\n",
    "print(coefs2)\n",
    "print('')\n",
    "print(intercept2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Are the individual coefficients ‘‘statistically significant’’?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00528824, 0.00799067, 0.10762718])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To answer this we need new t-scores to find the p-Values for the coefficients obtained\n",
    "t_scores2 = coefs2 / (np.std(x2)/np.sqrt(500))\n",
    "p_values2 = scipy.stats.t.sf(np.abs(t_scores2), df=500)*2\n",
    "p_values2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-values of each of the coefficients we have obtained show that the first 2 are below the 5% threshold and such are statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What about the omnibus F? What happens to the p-values compared to part (a)?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F-Statistic for this data is = 4.996963590451705\n",
      "\n",
      "The p-value for the F-Statistic is = 0.002010797206169812\n"
     ]
    }
   ],
   "source": [
    "y_hat = reg2.predict(x2) #can our regression predict X?\n",
    "y_mean = np.mean(y)\n",
    "RSS = sum((y-y_hat)**2)\n",
    "TSS = sum((y-y_mean)**2)\n",
    "RegSS = TSS-RSS\n",
    "R2 = RegSS/TSS \n",
    "\n",
    "F_statistic_b = (R2/3)/((1-R2)/(496))\n",
    "print('The F-Statistic for this data is = {}'.format(F_statistic_b))\n",
    "print('')\n",
    "p_value_f_stat_b = 1 - scipy.stats.f.cdf(F_statistic_b,3,497)\n",
    "print('The p-value for the F-Statistic is = {}'.format(p_value_f_stat_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F-statistic for part A= 1.1391748281640006 vs part C= 4.996963590451705\n",
      "\n",
      "The p-value for the F-statistic of part A= 0.19340917074425557 vs part C= 0.002010797206169812\n"
     ]
    }
   ],
   "source": [
    "print('The F-statistic for part A= {} vs part C= {}'.format(F_statistic_a,F_statistic_b))\n",
    "print('\\nThe p-value for the F-statistic of part A= {} vs part C= {}'.format(p_value_f_stat_a,p_value_f_stat_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we observe that the F-Statistic is ~5 with a p-value below the 5% threshold, thus, the F-statistic is significantly significant and we reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Using any method of variable selection (stepwise regression or subset regression with any criterion), find the ‘‘best’’ model with three explanatory variables. Obtain the individual t-statistics and omnibus F for this model. How do these tests compare to those in part (a)?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''First we create a function for the Forward variable selection obtained at\n",
    "https://www.datasklr.com/ols-least-squares-regression/variable-selection '''\n",
    "\n",
    "def forward_var_selection(x, y, threshold_in):\n",
    "    initial_list = []\n",
    "    best_pvalues = []\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        excluded = list(set(x.columns)-set(included))\n",
    "        new_pval = pd.Series(dtype='float64',index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            best_pvalues.append(best_pval) \n",
    "            changed=True\n",
    "        if not changed:\n",
    "            break\n",
    "    return included, best_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 83, 35, 18, 53]\n",
      "\n",
      "[0.00428503197962777, 0.009237603352237186, 0.014222822981944059, 0.012131844976330547, 0.019637144374317128]\n"
     ]
    }
   ],
   "source": [
    "#Apply the above Forward variable selection to our initial data \n",
    "\n",
    "X = data.iloc[:, 1:]\n",
    "y = data[0]\n",
    "best_expl_variables, best_pvalues = forward_var_selection(X, y, 0.05)\n",
    "print(best_expl_variables)\n",
    "print('')\n",
    "print(best_pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 83, 18]\n"
     ]
    }
   ],
   "source": [
    "#Find the top 3 explanatory variables \n",
    "top3_explvar = [i for _, i in sorted(zip(best_pvalues,best_expl_variables))][:3]\n",
    "print(top3_explvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Obtain the individual t-statistics and omnibus F for this model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1291325  -0.12299774  0.11676604]\n",
      "\n",
      "0.05374555707485369\n",
      "\n",
      "[0.0042597  0.00592506 0.00884849]\n"
     ]
    }
   ],
   "source": [
    "x3 = data[top3_explvar]\n",
    "y = data[0]\n",
    "reg3 = LinearRegression().fit(x3, y)\n",
    "coefs3 = reg3.coef_\n",
    "intercept3 = reg3.intercept_\n",
    "t_scores3 = coefs3/(np.std(x3)/np.sqrt(500))\n",
    "p_values3 = scipy.stats.t.sf(np.abs(t_scores3), df=500)*2\n",
    "\n",
    "print(coefs3) # 3 coefficients for each predictors\n",
    "print('')\n",
    "print(intercept3)\n",
    "print('')\n",
    "print(p_values3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44   -2.871422\n",
      "83   -2.763743\n",
      "18    2.628170\n",
      "dtype: float64\n",
      "\n",
      "The F-Statistic for this data is = 7.114598051316336\n",
      "\n",
      "The p-value for the F-Statistic is = 0.00010942657426105118\n"
     ]
    }
   ],
   "source": [
    "y_hat = reg3.predict(x3) #can our regression predict X3?\n",
    "y_mean = np.mean(y)\n",
    "RSS = sum((y-y_hat)**2)\n",
    "TSS = sum((y-y_mean)**2)\n",
    "RegSS = TSS-RSS\n",
    "R2 = RegSS/TSS \n",
    "\n",
    "print(t_scores3)\n",
    "print('')\n",
    "F_statistic_c = (R2/3) / ((1-R2)/(496))\n",
    "print('The F-Statistic for this data is = {}'.format(F_statistic_c))\n",
    "print('')\n",
    "p_value_f_stat_c = 1 - scipy.stats.f.cdf(F_statistic_c,3,497)\n",
    "print('The p-value for the F-Statistic is = {}'.format(p_value_f_stat_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`How do these tests compare to those in part (a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F-statistic for part A= 1.1391748281640006 vs part C= 7.114598051316336\n",
      "\n",
      "The p-value for the F-statistic of part A= 0.19340917074425557 vs part C= 0.00010942657426105118\n"
     ]
    }
   ],
   "source": [
    "print('The F-statistic for part A= {} vs part C= {}'.format(F_statistic_a,F_statistic_c))\n",
    "print('\\nThe p-value for the F-statistic of part A= {} vs part C= {}'.format(p_value_f_stat_a,p_value_f_stat_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the F-statistic for the forward variable selection is statistically significant but for part A, it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Using the methods of model selection discussed in this chapter, find the ‘‘best’’ model for these data. How does that model compare to the true model that generated the data?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 101\n",
      "MSE: 0.895\n",
      "AIC: 146.526\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Draft functions to apply the Akaile Information Selection (AIC) Model Selection. This code snipit is \n",
    "taken from https://machinelearningmastery.com/probabilistic-model-selection-measures/ section on AIC.\n",
    "AIC works by evaluating the model’s fit on the training data, and adding a penalty term for the complexity \n",
    "of the model (similar fundamentals to regularization). The desired result is to find the lowest possible\n",
    "AIC, which indicates the best balance of model fit with generalizability.\"\"\"\n",
    "\n",
    "#Model 1: Part A\n",
    "def calculate_aic(n, mse, num_params):\n",
    "    aic = n * log(mse) + 2 * num_params\n",
    "    return aic\n",
    " \n",
    "y = data[0]\n",
    "X = data.iloc[:, 1:]\n",
    "reg4 = LinearRegression().fit(X, y)\n",
    "num_params = len(reg4.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = reg4.predict(X)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the aic\n",
    "aic = calculate_aic(len(y), mse, num_params)\n",
    "print('AIC: %.3f' % aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4\n",
      "MSE: 1.117\n",
      "AIC: 63.215\n"
     ]
    }
   ],
   "source": [
    "#Model 2, Part B\n",
    "reg5 = LinearRegression().fit(x2, y)\n",
    "num_params = len(reg5.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = reg5.predict(x2)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the aic\n",
    "aic = calculate_aic(len(y), mse, num_params)\n",
    "print('AIC: %.3f' % aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4\n",
      "MSE: 1.103\n",
      "AIC: 57.037\n"
     ]
    }
   ],
   "source": [
    "#Model 3, Part C\n",
    "reg6 = LinearRegression().fit(x3, y)\n",
    "num_params = len(reg6.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = reg6.predict(x3)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the aic\n",
    "aic = calculate_aic(len(y), mse, num_params)\n",
    "print('AIC: %.3f' % aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 101\n",
      "MSE: 0.895\n",
      "BIC: 572.201\n"
     ]
    }
   ],
   "source": [
    "#Calculate BIC for Model 1, Part A Linear Regression\n",
    "def calculate_bic(n, mse, num_params):\n",
    "    bic = n * log(mse) + num_params * log(n)\n",
    "    return bic\n",
    " \n",
    "y = data[0]\n",
    "X = data.iloc[:, 1:]\n",
    "reg7 = LinearRegression().fit(X, y)\n",
    "num_params = len(reg7.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = reg7.predict(X)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the bic\n",
    "bic = calculate_bic(len(y), mse, num_params)\n",
    "print('BIC: %.3f' % bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4\n",
      "MSE: 1.117\n",
      "BIC: 80.073\n"
     ]
    }
   ],
   "source": [
    "#Part B\n",
    "reg8 = LinearRegression().fit(x2, y)\n",
    "num_params = len(reg8.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = reg8.predict(x2)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the bic\n",
    "bic = calculate_bic(len(y), mse, num_params)\n",
    "print('BIC: %.3f' % bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4\n",
      "MSE: 1.103\n",
      "BIC: 73.895\n"
     ]
    }
   ],
   "source": [
    "#Part C\n",
    "reg9 = LinearRegression().fit(x3, y)\n",
    "num_params = len(reg9.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = reg9.predict(x3)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the bic\n",
    "bic = calculate_bic(len(y), mse, num_params)\n",
    "print('BIC: %.3f' % bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have a lower AIC and BIC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Validation: Generate a new set of 500 observations as in part (a), and use that new data set to validate the models that you selected in parts (b), (c), and (d). What do you conclude?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051992</td>\n",
       "      <td>0.899764</td>\n",
       "      <td>0.589070</td>\n",
       "      <td>0.261109</td>\n",
       "      <td>-0.666773</td>\n",
       "      <td>-0.104549</td>\n",
       "      <td>0.506363</td>\n",
       "      <td>1.225550</td>\n",
       "      <td>0.777034</td>\n",
       "      <td>0.030659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550585</td>\n",
       "      <td>1.382150</td>\n",
       "      <td>-2.118320</td>\n",
       "      <td>-0.889672</td>\n",
       "      <td>-0.607861</td>\n",
       "      <td>-0.153339</td>\n",
       "      <td>0.750018</td>\n",
       "      <td>-0.266946</td>\n",
       "      <td>0.172416</td>\n",
       "      <td>0.226511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548305</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>-0.229710</td>\n",
       "      <td>0.089315</td>\n",
       "      <td>1.410368</td>\n",
       "      <td>0.217488</td>\n",
       "      <td>0.345870</td>\n",
       "      <td>0.296255</td>\n",
       "      <td>-1.034479</td>\n",
       "      <td>0.735787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345107</td>\n",
       "      <td>1.245537</td>\n",
       "      <td>0.566385</td>\n",
       "      <td>-0.511872</td>\n",
       "      <td>0.741763</td>\n",
       "      <td>0.440613</td>\n",
       "      <td>1.737936</td>\n",
       "      <td>0.393390</td>\n",
       "      <td>0.094591</td>\n",
       "      <td>1.074160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.780616</td>\n",
       "      <td>-0.551527</td>\n",
       "      <td>-1.994074</td>\n",
       "      <td>1.913004</td>\n",
       "      <td>-0.743202</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.338675</td>\n",
       "      <td>0.060938</td>\n",
       "      <td>-0.590702</td>\n",
       "      <td>0.565335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.988265</td>\n",
       "      <td>-2.239318</td>\n",
       "      <td>-0.019485</td>\n",
       "      <td>1.376795</td>\n",
       "      <td>1.245656</td>\n",
       "      <td>1.310724</td>\n",
       "      <td>-0.617499</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.402856</td>\n",
       "      <td>-0.926268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.542025</td>\n",
       "      <td>-1.404280</td>\n",
       "      <td>-0.114562</td>\n",
       "      <td>0.777305</td>\n",
       "      <td>0.784420</td>\n",
       "      <td>1.483142</td>\n",
       "      <td>0.151873</td>\n",
       "      <td>-1.042084</td>\n",
       "      <td>-0.793184</td>\n",
       "      <td>0.062786</td>\n",
       "      <td>...</td>\n",
       "      <td>1.756568</td>\n",
       "      <td>1.647429</td>\n",
       "      <td>-1.451927</td>\n",
       "      <td>0.052422</td>\n",
       "      <td>-2.024718</td>\n",
       "      <td>0.142019</td>\n",
       "      <td>-0.517535</td>\n",
       "      <td>0.709141</td>\n",
       "      <td>0.772074</td>\n",
       "      <td>-1.101387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.610526</td>\n",
       "      <td>-1.264492</td>\n",
       "      <td>-0.830053</td>\n",
       "      <td>-1.410610</td>\n",
       "      <td>1.023379</td>\n",
       "      <td>0.159876</td>\n",
       "      <td>-0.471192</td>\n",
       "      <td>-0.708406</td>\n",
       "      <td>-1.451398</td>\n",
       "      <td>-0.974284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307873</td>\n",
       "      <td>-0.430515</td>\n",
       "      <td>2.085424</td>\n",
       "      <td>1.646550</td>\n",
       "      <td>0.627264</td>\n",
       "      <td>0.978643</td>\n",
       "      <td>0.484822</td>\n",
       "      <td>0.330350</td>\n",
       "      <td>-1.020259</td>\n",
       "      <td>0.285352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.587863</td>\n",
       "      <td>-0.727626</td>\n",
       "      <td>1.280593</td>\n",
       "      <td>-1.466898</td>\n",
       "      <td>0.513573</td>\n",
       "      <td>-0.848437</td>\n",
       "      <td>1.358403</td>\n",
       "      <td>1.722591</td>\n",
       "      <td>1.365443</td>\n",
       "      <td>1.275658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707980</td>\n",
       "      <td>1.113306</td>\n",
       "      <td>1.246727</td>\n",
       "      <td>0.643577</td>\n",
       "      <td>0.487650</td>\n",
       "      <td>-0.232476</td>\n",
       "      <td>-1.472751</td>\n",
       "      <td>-1.835942</td>\n",
       "      <td>1.705611</td>\n",
       "      <td>-0.952521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.358722</td>\n",
       "      <td>1.485203</td>\n",
       "      <td>-0.360121</td>\n",
       "      <td>0.320817</td>\n",
       "      <td>-0.124765</td>\n",
       "      <td>0.261956</td>\n",
       "      <td>0.120995</td>\n",
       "      <td>1.446888</td>\n",
       "      <td>-1.039337</td>\n",
       "      <td>-0.971614</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.481245</td>\n",
       "      <td>-0.638567</td>\n",
       "      <td>0.541925</td>\n",
       "      <td>-0.733734</td>\n",
       "      <td>-0.175477</td>\n",
       "      <td>-2.018436</td>\n",
       "      <td>-0.660938</td>\n",
       "      <td>-0.180823</td>\n",
       "      <td>0.741476</td>\n",
       "      <td>0.337785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.180030</td>\n",
       "      <td>-1.329998</td>\n",
       "      <td>0.142811</td>\n",
       "      <td>-1.972297</td>\n",
       "      <td>-0.487808</td>\n",
       "      <td>1.182503</td>\n",
       "      <td>0.180282</td>\n",
       "      <td>1.425742</td>\n",
       "      <td>0.583114</td>\n",
       "      <td>2.451730</td>\n",
       "      <td>...</td>\n",
       "      <td>2.360226</td>\n",
       "      <td>0.871831</td>\n",
       "      <td>0.665856</td>\n",
       "      <td>-1.496330</td>\n",
       "      <td>-0.600331</td>\n",
       "      <td>-1.358570</td>\n",
       "      <td>0.718267</td>\n",
       "      <td>-1.838843</td>\n",
       "      <td>0.170791</td>\n",
       "      <td>-1.627576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.814214</td>\n",
       "      <td>-0.390716</td>\n",
       "      <td>1.316339</td>\n",
       "      <td>1.426041</td>\n",
       "      <td>-0.317919</td>\n",
       "      <td>0.377338</td>\n",
       "      <td>-1.584713</td>\n",
       "      <td>0.486882</td>\n",
       "      <td>0.856261</td>\n",
       "      <td>-0.697047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824064</td>\n",
       "      <td>1.478910</td>\n",
       "      <td>-0.632329</td>\n",
       "      <td>0.588199</td>\n",
       "      <td>0.346138</td>\n",
       "      <td>-0.357904</td>\n",
       "      <td>0.465383</td>\n",
       "      <td>-1.304417</td>\n",
       "      <td>-0.474953</td>\n",
       "      <td>-0.416133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1.190685</td>\n",
       "      <td>0.069379</td>\n",
       "      <td>0.665862</td>\n",
       "      <td>-0.934316</td>\n",
       "      <td>0.172199</td>\n",
       "      <td>-2.564470</td>\n",
       "      <td>0.107774</td>\n",
       "      <td>-0.079401</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>-0.916488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053514</td>\n",
       "      <td>-1.255336</td>\n",
       "      <td>0.609463</td>\n",
       "      <td>-0.291177</td>\n",
       "      <td>1.173757</td>\n",
       "      <td>0.772087</td>\n",
       "      <td>0.994617</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.838737</td>\n",
       "      <td>1.348515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.051992  0.899764  0.589070  0.261109 -0.666773 -0.104549  0.506363   \n",
       "1    0.548305  0.466000 -0.229710  0.089315  1.410368  0.217488  0.345870   \n",
       "2   -1.780616 -0.551527 -1.994074  1.913004 -0.743202  0.313345  0.338675   \n",
       "3   -0.542025 -1.404280 -0.114562  0.777305  0.784420  1.483142  0.151873   \n",
       "4    0.610526 -1.264492 -0.830053 -1.410610  1.023379  0.159876 -0.471192   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "495  0.587863 -0.727626  1.280593 -1.466898  0.513573 -0.848437  1.358403   \n",
       "496 -0.358722  1.485203 -0.360121  0.320817 -0.124765  0.261956  0.120995   \n",
       "497  0.180030 -1.329998  0.142811 -1.972297 -0.487808  1.182503  0.180282   \n",
       "498  0.814214 -0.390716  1.316339  1.426041 -0.317919  0.377338 -1.584713   \n",
       "499  1.190685  0.069379  0.665862 -0.934316  0.172199 -2.564470  0.107774   \n",
       "\n",
       "          7         8         9    ...       91        92        93   \\\n",
       "0    1.225550  0.777034  0.030659  ...  0.550585  1.382150 -2.118320   \n",
       "1    0.296255 -1.034479  0.735787  ...  0.345107  1.245537  0.566385   \n",
       "2    0.060938 -0.590702  0.565335  ... -0.988265 -2.239318 -0.019485   \n",
       "3   -1.042084 -0.793184  0.062786  ...  1.756568  1.647429 -1.451927   \n",
       "4   -0.708406 -1.451398 -0.974284  ...  0.307873 -0.430515  2.085424   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "495  1.722591  1.365443  1.275658  ...  0.707980  1.113306  1.246727   \n",
       "496  1.446888 -1.039337 -0.971614  ... -1.481245 -0.638567  0.541925   \n",
       "497  1.425742  0.583114  2.451730  ...  2.360226  0.871831  0.665856   \n",
       "498  0.486882  0.856261 -0.697047  ...  0.824064  1.478910 -0.632329   \n",
       "499 -0.079401  0.527821 -0.916488  ...  0.053514 -1.255336  0.609463   \n",
       "\n",
       "          94        95        96        97        98        99        100  \n",
       "0   -0.889672 -0.607861 -0.153339  0.750018 -0.266946  0.172416  0.226511  \n",
       "1   -0.511872  0.741763  0.440613  1.737936  0.393390  0.094591  1.074160  \n",
       "2    1.376795  1.245656  1.310724 -0.617499  0.007686  0.402856 -0.926268  \n",
       "3    0.052422 -2.024718  0.142019 -0.517535  0.709141  0.772074 -1.101387  \n",
       "4    1.646550  0.627264  0.978643  0.484822  0.330350 -1.020259  0.285352  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "495  0.643577  0.487650 -0.232476 -1.472751 -1.835942  1.705611 -0.952521  \n",
       "496 -0.733734 -0.175477 -2.018436 -0.660938 -0.180823  0.741476  0.337785  \n",
       "497 -1.496330 -0.600331 -1.358570  0.718267 -1.838843  0.170791 -1.627576  \n",
       "498  0.588199  0.346138 -0.357904  0.465383 -1.304417 -0.474953 -0.416133  \n",
       "499 -0.291177  1.173757  0.772087  0.994617  0.015412  0.838737  1.348515  \n",
       "\n",
       "[500 rows x 101 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr2 = np.random.normal(0, 1, size=(500, 101))\n",
    "data2 = pd.DataFrame(arr2)\n",
    "display(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score of method in Part B =  -0.009328681246458715\n",
      "Cross Validation Score of method in Part C =  -0.01435957016381011\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "#Part B\n",
    "X_train_b = data[top3_tscores]\n",
    "y_train_b = data[0]\n",
    "X_test_b = data2[top3_tscores]\n",
    "y_test_b = data2[0]\n",
    "lr.fit(X_train_b, y_train_b)\n",
    "score = cross_val_score(lr, X_test_b, y_test_b, cv=5)\n",
    "print(\"Cross Validation Score of method in Part B = \", score.mean())\n",
    "\n",
    "#Part C\n",
    "X_train_c = data[top3_explvar]\n",
    "y_train_c = data[0]\n",
    "X_test_c = data2[top3_explvar]\n",
    "y_test_c = data2[0]\n",
    "lr.fit(X_train_c, y_train_c)\n",
    "score = cross_val_score(lr, X_test_c, y_test_c, cv=5)\n",
    "print(\"Cross Validation Score of method in Part C = \", score.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
